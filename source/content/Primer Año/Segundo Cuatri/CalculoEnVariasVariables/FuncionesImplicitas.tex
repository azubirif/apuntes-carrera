%TEX root = Calculo.tex

\documentclass{../Calculo.tex}

\begin{document}
\chapter{Funciones Implícitas}
\section{Funciones Inversas}
Dada $f: A \to B$, se dice que $f$ tiene inversa si existe una función $g: B \to A$ tal que
\[
	f\circ g = Id_{b}
\]
y similarmente
\[
	g \circ f = Id_{a}
\]
Si esta función existe, se denota por
\[
	f^{-1} \neq \frac{1}{f}
\]
Se puede demostrar que $f^{-1}$ existe si y solo si $f$ es inyectiva y sobreyectiva (biyectiva). Sin embargo, dadas ciertas funciones que no sean ni inyectivas ni sobreyectivas, se pueden restringir de forma que sean biyectivas.\\
\textbf{Ejemplos}:
\begin{itemize}
	\item $f(x)=x ^{2}$. Esta función es sobreyectiva, pero no es inyectiva, y por tanto no tiene inversa. Sin embargo, podemos restringir el dominio tal que $x\geq 0$, y entonces sí que es inyectiva, por tanto biyectiva, y por tanto tiene inversa.
	\item $g(x)=\cos x$. Esta función es periódica, pero si restringimos la función a un período $[0, \pi]$, entonces es biyectiva.  
\end{itemize}
Sea $\bar{f}(\mathbf{x}) = \mathbf{y}$. Queremos ver si podemos invertir esta relación $(\bar{f}^{-1})$, y obtener
\[
	\mathbf{x} = \bar{f}^{-1}(\mathbf{y})
\]
Para ello, introducimos el siguiente teorema.
\begin{teorema}[Teorema de la función inversa]
	Dada una función $f:\mathbb{R}^{n} \to \R^{n}$, esta tiene inversa si y solo si el determinante jacobiano (determinante de su diferencial) es distinto a $0$.  
\end{teorema}
\pagebreak
	Dado un sistema de ecuaciones, no necesariamente lineales, siempre lo podemos escribir de la forma:
	\begin{equation}
		\begin{split}
			f_{1}(x_1,\dots ,x_{n+k})&=0\\
			\dots \\
			f_{n}(x_1,\dots ,x_{n+k})&=0
		\end{split}
	\end{equation}
	Vamos a analizar en qué condiciones podemos despejar $n$ incógnitas en función de las $k$ restantes, que serían parámetros libres. En este caso, estas ecuaciones describen un objeto de $k$ dimensiones en $\mathbb{R}^{n+k}$. Para distinguir entre parámetros libres e incógnitas, introduciremos la siguiente notación:
\begin{itemize}
	\item Las incógnitas son $x_{i},\dots ,x_{n}$.
	\item Los parámetros libres serán $t_1=x_{n+1},\dots ,t_{k}=x_{n+k}$. 
\end{itemize}
Además, introduciremos la función vectorial $\bar{f}=(f_1,\dots ,f_{n})$, entonces el sistema a resolver acaba siendo
\[
	\bar{f}(\mathbf{x}, \mathbf{t})=\mathbf{0}
\]
Ahora, supongamos que $(\mathbf{x}_{0}, \mathbf{t}_{0})$ es una solución del sistema que cumple la ecuación anteriormente establecida, y que además $\bar{f} \in \mathcal{C}^{1}$. Entonces, podemos hacer la aproximación
\[
	\bar{f}(\mathbf{x}, \mathbf{t}) \approx \bar{f}(\mathbf{x}_{0}, \mathbf{t}_{0})+D \bar{f}(\mathbf{x}_{0}, \mathbf{t}_{0})(\mathbf{x}-\mathbf{x}_{0}, \mathbf{t}-\mathbf{t}_{0})
\]
Como hemos asumido que la anterior tupla era solución del sistema, y queremos una solución a la ecuación, queda
\[
	D \bar{f}(\mathbf{x}_{0}, \mathbf{t}_{0})(\mathbf{x}-\mathbf{x}_{0},\mathbf{t}-\mathbf{t}_{0})=\mathbf{0}
\]
Si escribimos explícitamente el diferencial, obtenemos que
\[
	\begin{bmatrix}
	
		\pdv{f_1}{x_1}&\dots &\pdv{f_1}{x_{n}} & \pdv{f_1}{t_1}&\dots &\pdv{f_1}{t_{k}}\\
		\dots \\
		\pdv{f_{n}}{x_{1}}&\dots &\pdv{f_{n}}{x_{n}}&\pdv{f_{n}}{t_{1}}&\dots &\pdv{f_{n}}{t_{k}}
	
	\end{bmatrix}^{\text{Evaluado en }(\mathbf{x_{0}}, \mathbf{t}_{0})}\cdot (\mathbf{x}-\mathbf{x}_{0}, \mathbf{t}-\mathbf{t}_{0})= \mathbf{0}
\]
Aquí sigue que
\[
	\left(D_{x} \bar{f}(\mathbf{x_{0}}, \mathbf{t_0}),D_{t}\bar{f}(\mathbf{x}_{0}, \mathbf{t}_{0}) \right)(\mathbf{x}-\mathbf{x}_{0}, \mathbf{t}-\mathbf{t}_{0})=\mathbf{0}
\]
Reordenando y simplificando, obtenemos que debe existir la inversa de la matriz $D_{x} \bar{f}$, y por tanto su determinante debe ser distinto a $0$.
\begin{defin}
Dada una función $f:D \subset \mathbb{R}^{n} \to \mathbb{R}$, y sea $\mathbf{a} \in D$, $f$ tiene un mínimo absoluto en $\mathbf{a}$ si
\[
	f(\mathbf{a}) \leq f(\mathbf{x}) \forall \mathbf{x} \in D
\]
\end{defin}
La definición de máximo es análoga.
\begin{defin}[Mínimo local]
Esta definición sigue de tomar los puntos en una cierta bola. Es decir, un punto $\mathbf{a}$ será mínimo local en $B_{\delta}$ si y solo si
\[
	f(\mathbf{a}) \leq f(\mathbf{x}) \forall \mathbf{x} \in B_{\delta}
\]
\end{defin}
\section{Extremos de funciones escalares}
Usaremos con frecuencia el siguiente teorema:
\begin{teorema}
Sea $f:D \subset \mathbb{R}^{n} \to \mathbb{R}$ una función diferenciable en $\mathbf{a} \in int(D)$. Si $f$ tiene un extremo local en $\mathbf{a}$, entonces
\[
	\nabla f(\mathbf{a}) = 0
\]
\end{teorema}
\begin{proof}[Demostración]
Hallemos la derivada de $f$ respecto de un vector $\mathbf{v} \in \mathbb{R}^{n}$ cualquiera:
\begin{equation}
	\begin{split}
		f'(\mathbf{a}, \mathbf{v}) &= \lim_{h \to 0} \frac{f(\mathbf{a}+h \mathbf{v})-f(\mathbf{a})}{h}
	\end{split}
\end{equation}
Sabemos que este límite existe ya que $f$ es diferenciable. Supongamos que $f$ tiene un mínimo local en $\mathbf{a}$. En particular, también existen los límites laterales en $\mathbf{x}=\mathbf{a}$.\\
Si $f$ tiene un mínimo local en $\mathbf{a}$, entonces
\[
	f(\mathbf{a}+h \mathbf{v})-f(\mathbf{a}) \geq 0
\]
para un $h$ lo suficientemente pequeño. Entonces, la derivada lateral en ese punto, $f'(\mathbf{a}, \mathbf{v})^{+} \geq 0$. Y la otra derivada lateral, cumple que $f'(\mathbf{a}, \mathbf{v})^{-} \leq 0$. Para que ambas ecuaciones se cumplan, y teniendo en cuenta que es diferenciable:
\[
	f'(\mathbf{a}, \mathbf{v})= \nabla f(\mathbf{a}) \cdot \mathbf{v} =0
\]
Como esto se debe cumplir para todos los vectores, entonces el gradiente es perpendicular a todos los vectores. El único que lo cumple es
\[
	\nabla f(\mathbf{a}) = 0
\]
\end{proof}
\end{document}
